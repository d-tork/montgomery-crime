input {
	file {
		path => "/Volumes/Maxtor/crime/Montgomery_county_crime.csv"
		# read mode ONLY
		#mode => "read"
		#exit_after_read => true
		file_chunk_count => 5
		file_chunk_size => 32768
		# ignored in read mode: 
		start_position => "beginning"
		sincedb_path => "/dev/null"
  }
}

filter {
	csv {
		separator => ","
		autodetect_column_names => true
		skip_header => true
	}

	dissect {
		mapping => {
			"Location" => "(%{lat}, %{lon})"
			}
		add_field => {
			"geolocation2" => "%{lat},%{lon}"
			}
	}
	mutate {
		add_field => {
			"geolocation1" => "%{Latitude},%{Longitude}"
		}
	}

	mutate { rename => {"Dispatch Date / Time" => "Dispatch_Date_Time"} }
	if [Dispatch_Date_Time] {
		date {
			match => ["Dispatch_Date_Time", "MM/dd/yyyy HH:mm:ss a"]
			target => "Dispatch_Date_Time"
			}
		}
	date {
		match => ["Start_Date_Time", "MM/dd/yyyy HH:mm:ss a"]
		target => "Start_Date_Time"
		}
	date {
		match => ["Start_Date_Time", "MM/dd/yyyy HH:mm:ss a"]
		}
	if [End_Date_Time] {
		date {
			match => ["End_Date_Time", "MM/dd/yyyy HH:mm:ss a"]
			target => "End_Date_Time"
			}
		}
}

output {
	elasticsearch {
		template => "/Volumes/Maxtor/crime/Montgomery_index_template.json"
		template_overwrite => true
		action => "index"
		hosts => "192.168.1.145"
		index => crime_montgomery_1
		workers => 1
	}
	stdout {}
}
